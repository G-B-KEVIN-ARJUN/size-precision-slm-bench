{
  "Qwen-2.5-3B": {
    "throughput": 22.386677517517743,
    "bert_score": 0.879499363899231,
    "runs": [
      {
        "latency": 4.300833702087402,
        "speed_tps": 18.136018596148656,
        "ttft": 1.0875506401062012,
        "tpot": 0.041730948856898716
      },
      {
        "latency": 3.858522415161133,
        "speed_tps": 22.288324583027883,
        "ttft": 0.1470184326171875,
        "tpot": 0.04366475273581112
      },
      {
        "latency": 4.633384704589844,
        "speed_tps": 23.956568918191294,
        "ttft": 0.25402164459228516,
        "tpot": 0.03981239145452326
      },
      {
        "latency": 2.7961132526397705,
        "speed_tps": 23.96183342600528,
        "ttft": 0.09000134468078613,
        "tpot": 0.041001695575136124
      },
      {
        "latency": 2.416212320327759,
        "speed_tps": 23.590642064215597,
        "ttft": 0.13519287109375,
        "tpot": 0.04073249016489301
      }
    ],
    "rouge": {
      "rouge1": 0.33893049896277194,
      "rouge2": 0.09504195863233432,
      "rougeL": 0.21877024677126278,
      "rougeLsum": 0.26570606713863
    },
    "bleu": {
      "bleu": 0.048852380858792496,
      "precisions": [
        0.2796833773087071,
        0.08288770053475936,
        0.02981029810298103,
        0.008241758241758242
      ],
      "brevity_penalty": 1.0,
      "length_ratio": 1.7227272727272727,
      "translation_length": 379,
      "reference_length": 220
    }
  },
  "Gemma-2-2B": {
    "throughput": 23.397255311683296,
    "bert_score": 0.8774979948997498,
    "runs": [
      {
        "latency": 4.2697412967681885,
        "speed_tps": 20.610147988733676,
        "ttft": 0.663616418838501,
        "tpot": 0.04144971124057112
      },
      {
        "latency": 4.352915525436401,
        "speed_tps": 24.121763766475397,
        "ttft": 0.13724279403686523,
        "tpot": 0.04053531472499554
      },
      {
        "latency": 4.945644855499268,
        "speed_tps": 23.65717786425826,
        "ttft": 0.24524497985839844,
        "tpot": 0.04052068858311094
      },
      {
        "latency": 4.362244129180908,
        "speed_tps": 24.528659293557517,
        "ttft": 0.08286833763122559,
        "tpot": 0.04037146973160078
      },
      {
        "latency": 3.448486804962158,
        "speed_tps": 24.068527645391644,
        "ttft": 0.11583113670349121,
        "tpot": 0.0406421422958374
      }
    ],
    "rouge": {
      "rouge1": 0.3482714065704865,
      "rouge2": 0.1256270203808194,
      "rougeL": 0.22837928222272375,
      "rougeLsum": 0.2666460413454075
    },
    "bleu": {
      "bleu": 0.06735456975395004,
      "precisions": [
        0.27233115468409586,
        0.0881057268722467,
        0.042316258351893093,
        0.02027027027027027
      ],
      "brevity_penalty": 1.0,
      "length_ratio": 2.0863636363636364,
      "translation_length": 459,
      "reference_length": 220
    }
  },
  "Llama-3.2-3B": {
    "throughput": 26.10907718336005,
    "bert_score": 0.8676552772521973,
    "runs": [
      {
        "latency": 4.883712530136108,
        "speed_tps": 24.980995348757737,
        "ttft": 0.3833639621734619,
        "tpot": 0.03719296337159212
      },
      {
        "latency": 5.318817853927612,
        "speed_tps": 26.697661754884486,
        "ttft": 0.16383028030395508,
        "tpot": 0.03656019555761459
      },
      {
        "latency": 5.925551414489746,
        "speed_tps": 25.48286048632703,
        "ttft": 0.2634541988372803,
        "tpot": 0.03774731477101644
      },
      {
        "latency": 4.120632171630859,
        "speed_tps": 26.69493306325964,
        "ttft": 0.1416471004486084,
        "tpot": 0.03650445019433258
      },
      {
        "latency": 4.795994997024536,
        "speed_tps": 26.688935263571366,
        "ttft": 0.13640975952148438,
        "tpot": 0.03668964753939411
      }
    ],
    "rouge": {
      "rouge1": 0.32065493627207176,
      "rouge2": 0.1477989116820737,
      "rougeL": 0.21826860030962575,
      "rougeLsum": 0.2738382342982937
    },
    "bleu": {
      "bleu": 0.06590129880736789,
      "precisions": [
        0.22818791946308725,
        0.09137055837563451,
        0.04778156996587031,
        0.0189328743545611
      ],
      "brevity_penalty": 1.0,
      "length_ratio": 2.709090909090909,
      "translation_length": 596,
      "reference_length": 220
    }
  }
}